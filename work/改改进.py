import pandas as pd
import numpy as np
import jieba
from sklearn.preprocessing import MinMaxScaler

# 加载数据
df = pd.read_excel(r'C:\Users\pc\Downloads\user_personalities_2d.xlsx')
score_columns = ['理性-感性得分', '幽默-严肃得分', '务实-理想得分', 
                '耐心-急躁得分', '直率-委婉得分', '温和-强硬得分']

# Min-Max标准化用户数据
scaler = MinMaxScaler()
user_scores_normalized = scaler.fit_transform(df[score_columns])

# 扩展后的关键词库（示例部分）
dimension_keywords = {
    '理性-感性': {
    'positive': [
        # 学术研究类
        '数据', '分析', '统计', '逻辑', '实证', '模型', '算法', '验证', '量化', '公式',
        '定理', '推导', '标准差', '回归分析', '假设检验', '因果', '论证', '框架', '方法论',
        '指标体系', '信效度', '抽样', '变量', '对照组', '双盲实验', '显著性', '协方差',
        '方差分析', '贝叶斯', '神经网络', '架构', '流程图', '接口', '模块化', '调试', '优化',
        '迭代', '封装', '自动化', '鲁棒性', '冗余', '容错率', '基准测试', '压力测试', '正交实验',
        '收敛性', '蒙特卡洛', '启发式', '时间复杂度', '空间复杂度', '可证伪性'
    ],
    'negative': [
        # 情感与主观体验
        '感受', '直觉', '共情', '感动', '流泪', '心痛', '温暖', '治愈', '情怀', '意境',
        '诗意', '浪漫', '情调', '触景生情', '睹物思人', '多愁善感', '美感', '韵律', '旋律',
        '构图', '写意', '蒙太奇', '意识流', '即兴', '灵感', '创作', '审美', '抽象派', '印象派',
        '超现实主义', '我觉得', '我相信', '我感受到', '个人认为', '私以为', '第六感', '心灵感应',
        '缘分', '命运', '灵魂', '禅意', '宿命', '直觉判断', '情感共鸣', '心灵震撼', '感同身受',
        '怦然心动', '潸然泪下', '怅然若失', '五味杂陈'
    ]
    },
    '幽默-严肃': {
    'positive': [
        # 幽默表达类
        '搞笑', '段子', '哈哈哈', '幽默', '趣闻', '笑话', '滑稽', '吐槽', '玩梗', '神回复',
        '谐音梗', '冷幽默', '反讽', '自嘲', '表情包', '恶搞', '脑洞', '无厘头', '反转', '调侃',
        '捧哏', '逗比', '笑喷', '笑死', '笑场', '爆笑', '妙啊', '沙雕', '鬼畜', '名场面',
        '谐星', '欢乐', '轻松', '趣味', '诙谐', '滑稽戏', '脱口秀', '相声', '小品', '模仿秀',
        '打油诗', '网络流行语', '颜文字', '熊猫头', '金句', '梗图', '玩坏', '灵魂拷问', '人间真实'
    ],
    'negative': [
        # 严肃讨论类
        '严肃', '认真', '探讨', '研究', '分析', '讨论', '论证', '学术', '严谨', '考据',
        '文献', '引证', '理论', '原理', '方法论', '逻辑链', '数据支持', '实验设计', '辩证', '批判',
        '反思', '深度', '本质', '根源', '系统性', '复杂性', '哲学', '思辨', '综述', '命题',
        '假说', '验证', '推导', '定理', '定律', '公式', '模型', '框架', '指标体系', '方法论',
        '学术规范', '参考文献', '同行评议', '量化分析', '实证研究', '双盲测试', '可重复性', '学术伦理'
    ]
    },
    '务实-理想': {
    'positive': [
        # 务实操作类
        '实用', '应用', '方法', '步骤', '操作', '经验', '案例', '建议', '教程', '手册',
        '指南', '攻略', '技巧', '窍门', '工具', '资源', '模板', '清单', '流程图', '时间表',
        '预算', '成本', '效率', '产出', '落地', '执行', '实施', '反馈', '改进', '迭代',
        '测试', '调试', '优化', '维护', '故障排除', '文档', '用户手册', 'SOP', 'KPI', 'ROI',
        '性价比', '快速上手', '即插即用', '开箱即用', '最佳实践', '避坑指南', '经验分享', '避雷', '实测'
    ],
    'negative': [
        # 理想愿景类
        '理想', '愿景', '梦想', '未来', '理念', '乌托邦', '蓝图', '设想', '可能性', '变革',
        '颠覆', '创新', '突破', '范式转移', '终极', '完美', '乌托邦', '理想国', '大同', '终极关怀',
        '哲学思考', '人类命运', '星辰大海', '探索未知', '无限可能', '永续发展', '终极答案', '形而上学',
        '本体论', '认识论', '价值判断', '存在主义', '自由意志', '道德律令', '普世价值', '终极目标',
        '理想主义', '乌托邦主义', '完美主义', '终极解决方案', '革命性', '范式革新', '重新定义', '颠覆性创新',
        '从0到1', '第二曲线', '升维思考', '元问题', '第一性原理'
    ]
    },
    '耐心-急躁': {
    'positive': [
        # 耐心培养类
        '耐心', '详细', '步骤', '指导', '解释', '帮助', '支持', '循序渐进', '分阶段', '分步骤',
        '手把手', '零基础', '小白友好', '入门指南', '常见问题', '注意事项', '避坑提示', '长期主义',
        '持续改进', '迭代优化', '反复练习', '熟能生巧', '温故知新', '阶段性总结', '定期反馈', '检查点',
        '里程碑', '时间管理', '番茄工作法', 'GTD', '任务分解', '优先级', '抗压能力', '延迟满足',
        '心流状态', '正念练习', '情绪管理', '压力缓解', '深呼吸', '冥想', '瑜伽', '渐进式', '分层次',
        '模块化学习', '知识体系', '系统化', '结构化', '思维导图', '复盘', 'PDCA循环'
    ],
    'negative': [
        # 急躁表现类
        '尽快', '急', '马上', '快', '速度', '赶紧', '紧急', '立刻', '立即', '火烧眉毛',
        '迫在眉睫', '刻不容缓', '十万火急', '赶时间', '没耐心', '跳步', '走捷径', '偷工减料',
        '敷衍了事', '三分钟热度', '浅尝辄止', '虎头蛇尾', '半途而废', '急躁', '浮躁', '焦虑',
        '压力山大', '崩溃', '抓狂', '原地爆炸', '心态炸裂', '没时间', '来不及', '截止日期',
        '倒计时', 'DDL', '通宵', '熬夜', '加班', '连轴转', '多任务', '分身乏术', '应接不暇',
        '手忙脚乱', '顾此失彼', '时间不够', '效率低下', '拖延症', '最后一刻'
    ]
    },
    '直率-委婉': {
    'positive': [
        # 直率表达类
        '必须', '显然', '确实', '当然', '无疑', '肯定', '绝对', '明确', '直接', '坦率',
        '直言不讳', '开门见山', '一针见血', '毫不掩饰', '直截了当', '单刀直入', '正面回应', '明确表态',
        '斩钉截铁', '毋庸置疑', '无可争辩', '板上钉钉', '铁证如山', '实锤', '实打实', '赤裸裸',
        '血淋淋', '尖锐', '犀利', '戳破', '揭穿', '打脸', '啪啪响', '不留情面', '撕破脸',
        '捅破窗户纸', '说破无毒', '直球', '硬刚', '正面硬怼', '不绕弯子', '有一说一', '明人不说暗话',
        '打开天窗说亮话', '话糙理不糙', '直给', '不藏着掖着'
    ],
    'negative': [
        # 委婉表达类
        '或许', '可能', '也许', '大概', '建议', '考虑', '不妨', '或者', '说不定', '说不定',
        '某种程度上', '某种意义上', '个人拙见', '仅供参考', '可能欠妥', '恐有不周', '有待商榷', '尚存疑问',
        '可能存在', '不排除', '或许可以', '从长计议', '从轻发落', '留有余地', '委婉', '含蓄', '暗示',
        '旁敲侧击', '弦外之音', '话里有话', '点到为止', '心照不宣', '看破不说破', '顾全大局', '留面子',
        '给台阶', '拐弯抹角', '绕圈子', '打太极', '和稀泥', '模棱两可', '含糊其辞', '避重就轻', '转移话题',
        '春秋笔法', '外交辞令', '场面话', '客套话', '官样文章', '虚与委蛇'
    ]
    },
    '温和-强硬': {
    'positive': [
        # 温和沟通类
        '建议', '考虑', '可以', '或许', '可能', '灵活', '协商', '讨论', '探讨', '商量',
        '请教', '请教', '劳驾', '麻烦', '辛苦', '感谢', '感恩', '包容', '理解', '体谅',
        '换位思考', '将心比心', '求同存异', '和而不同', '各退一步', '折中方案', '双赢', '共赢',
        '友好协商', '和平共处', '互相尊重', '平等对话', '理性讨论', '心平气和', '温文尔雅', '彬彬有礼',
        '以理服人', '循循善诱', '春风化雨', '润物无声', '点到为止', '留有余地', '适可而止', '见好就收',
        '得饶人处且饶人', '退一步海阔天空', '和气生财', '以柔克刚', '刚柔并济', '柔中带刚'
    ],
    'negative': [
        # 强硬态度类
        '必须', '绝对', '一定', '肯定', '严厉', '严格', '坚决', '绝不', '毫无', '完全',
        '彻底', '百分之百', '毋庸置疑', '没商量', '死命令', '硬性规定', '铁律', '红线', '底线',
        '零容忍', '一票否决', '强制', '强迫', '逼迫', '威胁', '恐吓', '最后通牒', '没得谈',
        '不容置疑', '说一不二', '独断专行', '刚愎自用', '固执己见', '一意孤行', '强词夺理', '咄咄逼人',
        '针锋相对', '寸步不让', '以势压人', '仗势欺人', '得理不饶人', '赶尽杀绝', '不留余地', '撕破脸',
        '鱼死网破', '玉石俱焚', '你死我活', '不共戴天', '势不两立', '血战到底'
    ]
    }
}

def analyze_question(text):
    words = list(jieba.cut(text))
    feature_vector = []
    for dim in score_columns:
        dim_name = dim.replace('得分', '')
        pos = sum(1 for w in words if w in dimension_keywords[dim_name]['positive'])
        neg = sum(1 for w in words if w in dimension_keywords[dim_name]['negative'])
        feature_vector.append(pos - neg)
    return np.array(feature_vector)

def recommend_users(question_vector):
    # 归一化向量
    q_norm = question_vector / np.linalg.norm(question_vector) if np.linalg.norm(question_vector)!=0 else question_vector
    similarities = []
    for user in user_scores_normalized:
        u_norm = user / np.linalg.norm(user)
        similarities.append(np.dot(q_norm, u_norm))
    df['相似度'] = similarities
    return df.sort_values('相似度', ascending=False).head(5)[['用户ID', '相似度'] + score_columns]

if __name__ == "__main__":
    questions = input("您想问的问题是：") 
    vec = analyze_question(questions)
    print(f"\n问题：{questions}")
    print(recommend_users(vec)[['用户ID', '相似度']].to_string(index=False))